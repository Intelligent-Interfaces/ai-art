\documentclass{evolang12}
\usepackage{graphicx}
\usepackage{float}
\usepackage{url}
\usepackage{authblk}
\usepackage{amsmath,mathtools, amsthm, amssymb}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}
\begin{document}


\title{A Community Generated Design Language: \\ From Fourier Analysis to Cultural Synthesis}
\author[*1]{ANONYMOUS AUTHOR 1}
\author[2]{ANONYMOUS AUTHOR 2}
\affil[*]{Corresponding Author: name@domain.com}
\affil[1]{This Department, University X, City, Country} % Center for Design Research, University of Kansas, Lawrence, USA
\affil[2]{That Department, University Y, City, Country} % HAMZA's affiliation...
\affil[3]{Other Department, University Z, City, Country} % HAMZA's/Erick's additional affiliation...

%%%%% INSTRUCTIONS FOR ADDING AUTHORS %%%%%

%Initial submissions should be anonymous - DO NOT INCLUDE ANY IDENTIFYING INFORMAITON IN THE SUBMISSION VERSION -(i.e., no author details should be added above). To avoid problems with page limits, please include the appropriate number of placeholders for authors. If multiple authors share an affiliation, they can be paired with the appropriate affiliation using the numbers in the square brackets next to "author" and "affil" to save space. Designate a single corresponding author using the asterisk.

%%%%% INSTRUCTIONS FOR ADDING AUTHORS %%%%%

% HAMZA-0: Could you please make sure we follow all of the guidelines according to:
% http://evolang.org/submissions

\maketitle
\abstracts{This design system explores the application of the fast Fourier transform (FFT) and genetically-inspired optimized automatic speech recognition-hidden Markov models (GMM-ASR-HMM) for the sake of providing novel shaped-based visualizations of some public space's acoustics. The design system runs on a mobile Linux-based computing system, where individuals can choose the characteristics of what is displayed  (i.e., color, complexity, shape type, and amount) through a graphical user interface. In doing so, participants collaborate with and contribute to an ever-evolving design by each providing input into the system's growing collection of preferences. Whether these collective and aggregated preferences are reflective of the communities, aesthetic value is a latent function of the system inferring structural representations for the environment's acoustical experience and in principle can learn from within any space.}

\section{Introduction}
\frenchspacing
The history and identity of a culture-community is regularly fossilized as artifacts generated by its participating members \cite{dor2015instruction,ferdinand2015inductive}. Such enduring cultural artifacts are resilient, surviving through replication from individual to individual and generation to generation. Over time, elements are naturally added, subtracted, substituted, and rearranged as they are transmitted from mind to mind \cite{ferdinand2015inductive}. Of course, culture is often materialized into \textit{physical structures} like the \textit{Gobirau Minaret} or \textit{Shinto shines}, which are the fruits of human cognitive and physical labor. However, It is the ideas or stories embodied in these artifacts that are truly subject to mutation and transmission, and provide inspiration for new structures and theories. On the other hand, cultural artifacts may be entirely social and immaterial, adapting through time, as in the case of natural languages like Arabic and English \cite{ferdinand2019cognitive,dor2015instruction} or fairy-tails (stories) such as \textit{Cinderella} and \textit{Little Red Riding Hood} \cite{stubbersfield2015serial,breithaupt2013disappearance}. 

Thus, the direction of this work is to use the perspective of cultural evolution as a foundation and various mathematical formulations to outline a framework that utilizes a generative design system, and its constituting \textit{learning algorithms} (LA), \textit{generative algorithms} (GAN), and \textit{genetic algorithms} (GA) to produce computer visualizations, where the visualizations are some function of the acoustic and frequency components of the sounds produced within a public space. 

% HAMZA-1: Could you write a paragraph about Neural Networks as an alternative form to GMM-HMM. I think writing it after the HMM section would be good. 

\subsection{Generative Design}
\textit{Generative design} refers to the generation of design solutions and alternatives, \textit{automatically} and \textit{iteratively} \cite{krish2011practical,sanguinetti2015automated}. Like \textit{parametric modelling}, through the specification of design parameters (e.g., materials, manufacturing methods, cost), generative design software explores the possible permutations of a solution, learning and improving after each iteration like genetic algorithms \cite{krish2011practical}. 

\paragraph{Evolutionary Algorithms}
The most direct computational analog to evolution, \textit{genetic algorithms} are a class of \textit{evolutionary algorithms} which utilize heuristics inspired from \textit{Darwinian natural selection} to find optimal design solutions \cite{kwong2001optimisation}. Genetic algorithms are a classic approach developed in computer science for performing continuous improvement within artificial and computational systems. In particular, some solution space is first populated randomly with individuals (solutions), each with some \textit{genotype} (coded as \textit{bit vectors}) and some level of \textit{fitness} (quality of solution) which can be transformed into the individual's virtual \textit{phenotype} or representation that can then be \textit{compared}, \textit{mutated}, or \textit{crossed} via \textit{variation operators} \cite{chau1997optimization}; producing subsequent generations (i.e., some set of \enquote{superior} quality solutions).

% ERICK: Do you want to keep this?
% \subsection{\textbf{Cultural Evolution}}
% Still, a question remains: \textit{What cognitive mechanisms are involved with the indirect replication, maintenance, and direct augmentation of culture?} Perhaps ideas, theories, and stories are passed on to guide subsequent community members through the complexities of their experience. Likewise, personal narratives may provide condensed forms of experience that are both reasonable and appealing, selecting ideals and knowledge gained from life happenings. These personal stories and larger cultural narratives are then circumlocutorily transmitted from person to person influencing how individuals within a community build representations of themselves and their culture. That is, there are \textit{fitness} processes at work, ideal and preferred representations of a community. Cognitive and social scientist use \textit{cultural evolution} -- a mechanistic theory developed to conceptualize the forces of evolution underlying change in culture over time, where the mechanisms of change are desirable within human cognition. In this domain, culture is often defined very broadly -- anything that replicates by passing through a cognitive system. To tease at the cognitive mechanism or biases involved in replication, researchers use \textit{linear transmission chains} to examine how people prefer to encoded certain particular aspects of content, where language games and drawing chain exercises are the primary stimulus for participants. Research using cultural transmission chains have shown how participants have a tendency to strip out moral choice in narrative content and show how content which is counter-intuitive or emotional is better cumulatively recalled in contrast to their non-emotional counterparts. , these cognitive mechanism and the resulting human artifacts are capable of shaping subsequent generations, their ecological community and environment.

% \subsection{Fourier Analysis}
% In this design system, the real-time input signal is represented by $s(t)$. Then, using the \textit{fast Fourier transform} (FFT), the spectro-temporal representation $S(f,t)$ is generated, which is a two dimensional representation of the input signal in the time-frequency product space. Typically, this spectro-temporal representation is a complex-valued function consisting of two components: the amplitude $|S(f,t)|$ and the frequency of phase $\phi(f,t)$. Thus, the full formulation is expressed as \cite{bruns2004fourier}:

% \begin{equation}
% S(f,t) = |S(f,t)|\cdot e^{i\phi(f,t)}
% \label{eq:fourier-transform}
% \end{equation}

\subsection{Hidden Markov Models}
\textit{Hidden Markov models} (HMMs) are a pervasive statistical tool used in a variety of fields. HMMs have demonstrated their utility within gene prediction, computational finance, metamorphic virus detection, cryptanalysis, and much more \cite{rabiner1986introduction,kohlschein2006introduction}. In fact, HMMs are known for modeling all sorts of sequential pattern processing and classification problems through a doubly stochastic process. One of the stochastic processes is a hidden sequence of states (Markov chain) that produce a sequence of random \textit{observable symbols}. This sequence of observable symbols are also governed by another stochastic process. Further, HMMs' namesake comes from its \textit{hidden states} fulfilling the \textit{Markov property} that is, the hidden state $x_{t+1}$ is independent of all states before state $x_{t}$ given the state value of $x_{t}$ \cite{kohlschein2006introduction}:

\begin{equation}
& P(X_{t+1} = x | X_{t} = x_{t}, X_{t-1} = x_{t-1},...,X_0 = X_0) = P(X_{t+1} = x_{t+1} | X_{t} = x_{t})
\label{eq:markov-assumption}
\end{equation}

In the case of this design system, the preferences are the observable symbols and the hidden states are the probable visualization.
\paragraph{Automatic Visualization Generation}
As it currently stands, in order to perform \textit{automatic visualization generation} (AVG) one must build the appropriate statistical model. In general, this process can be viewed as building computational modules, where at the crux is the decoder. In fact, this design system utilizes an ASR-based HMM framework \cite{gales2008application,young2002htk} which was originally designed for automatic speech recognition. A sort of head of operations, an AVG's \textit{decoder} is tasked with inferring the sequence of preferences $P_{1:L} = \left\{p_{1},p_{2}, \ ...\ ,p_{L}\right\}$ which is most likely to have generated the visualization $V$:
\begin{equation} \label{eq:1}
\widetilde{V} = \argmax_{X \in L}\ P(V | X)
\end{equation}
\noindent More generally, (\ref{eq:1}) aims to maximize the probability of a string of preferences within a design language $L$ given some user preference $P$. In this context, $P(V|X)$ turns out to be the product formed from the contribution of the AVG's \textit{Size model} $P(Size)$,\textit{Shape model} $P(Shape)$, and \textit{Color model} $P(Color)$
\begin{align}
\widetilde{V} = \argmax_{X \in L}\ P(Size)P(Shape)P(Color)
\end{align}

% Where $Q = \left\{q_{1},q_{2},\ ... \ ,q_{n}\right\}$ is the sequence of phonemes associated with the word $w$ (see  Fig.~\ref{EvoLang12-hmm-model.png}) and $O$ is the acoustic feature representation of $X$ that is derived from converting the input into a sequence of fixed size acoustic vectors $X_{1:T} = \left\{x_{1},x_{2}, \ ... \ ,x_{T}\right\}$ through conventional speech processing \textit{feature extraction} as shown in Fig.~\ref{EvoLang12-generic-asr_architecture-2.png}.  Traditionally, the decoder is HMM and \textit{Weighted Finite State Transducer} (WFST) combination \cite{gales2008application,povey2011kaldi,graves2013speech} as shown in Fig.~\ref{EvoLang12-generic-asr_architecture-2.png}.

% \paragraph{Automatic Generation and Recognition}
% As it currently stands, in order to perform \textit{automatic acoustic generation} (AAG) or \textit{automatic speech recognition} (ASR) one must build the appropriate statistical acoustic model. In general, this process can be viewed as building a collection of sub computational engines, where at the crux is the decoder. In fact, this design system utilizes an ASR-based HMM framework \cite{gales2008application,young2002htk} for AAG. A sort of head of operations, an ASR's \textit{decoder} is tasked with inferring the sequence of words $W_{1:L} = \left\{w_{1},w_{2}, \ ...\ ,w_{L}\right\}$ which ideally is most likely to have generated the speech (or audio) signal $X$
% \begin{equation} \label{eq:1}
% \widetilde{W} = \argmax_{W \in L}\ P(W | X)
% \end{equation}
% \noindent More generally, (\ref{eq:1}) aims to maximize the probability of a string of words within a Language $L$ given some acoustic input $X$. $P(W|X)$ turns out to be the product formed from the contribution of the ASR's \textit{pronunciation model} $P(Q|W)$,\textit{ acoustic model} $P(O|Q)$, and \textit{language model} $P(W)$
% \begin{align}
% \widetilde{W} = \argmax_{W \in L}\ P(O | Q)P(Q | W)P(W)
% \end{align}
% Where $Q = \left\{q_{1},q_{2},\ ... \ ,q_{n}\right\}$ is the sequence of phonemes associated with the word $w$ (see  Fig.~\ref{EvoLang12-hmm-model.png}) and $O$ is the acoustic feature representation of $X$ that is derived from converting the input into a sequence of fixed size acoustic vectors $X_{1:T} = \left\{x_{1},x_{2}, \ ... \ ,x_{T}\right\}$ through conventional speech processing \textit{feature extraction} as shown in Fig.~\ref{EvoLang12-generic-asr_architecture-2.png}.  Traditionally, the decoder is HMM and \textit{Weighted Finite State Transducer} (WFST) combination \cite{gales2008application,povey2011kaldi,graves2013speech} as shown in Fig.~\ref{EvoLang12-generic-asr_architecture-2.png}.

% Re: HAMZA-1: Maybe the GAN paragraph could go after here....
% HAMZA Notes:
% (Povey et al., 2011; Young et al., 2002), though recently, recurrent neural networks (RNN) and deep neural networks (DNN) (Graves, Mohamed, \& Hilton, 2013) have been used to make advancements in ASR technology. It should be noted, the traditional ASR framework (as shown in Figure 1) is highly configurable but also difficult to get up and running. In either case, the accuracy of these ASR systems fundamentally depends on the acoustic data
% and the application environment of the ASR system. 
% \paragraph{Alternative Generative Models}

\paragraph{Alternative Generative Models}
More recently, researchers in deep learning have found great success in generative design through the use of novel neural network architectures. The most prevalent architecture is known as a Generative Adversarial Network and is actually a combination of two competing neural networks \cite{NIPS2014_5423}. The first network, called the generator, takes in random numbers and produces new data instances while the second network, called the discriminator, evaluates whether this instance belongs to the original training data set. The generator is optimized to generate data instances that fool the discriminator whereas the discriminator is optimized to identify the generator's data instances as fakes. Thus, they train each other through a double feedback loop, the discriminator learning important features from the real data and the generator learning important features from the discriminator.


% Generic HMM-model
% \begin{figure}[H]
%  \centering
%  \includegraphics[width=0.80\textwidth]{EvoLang12-hmm-model.png}
%  \caption{The three-state left-to-right phoneme HMM}
%  \label{EvoLang12-hmm-model.png}
% \end{figure}

% Generic ASR
% \begin{figure}[H]
%  \centering
%  \includegraphics[width=0.80\textwidth]{EvoLang12-generic-asr_architecture-2.png}
%  \caption{Generic HMM-Decoding systems architecture}
%  \label{EvoLang12-generic-asr_architecture-2.png}
% \end{figure}

\paragraph{Synthesizing Foundations}
Ultimately, this design project aims to modestly integrate ideas from cultural evolution, machine learning, and generative design to construct a conceptual foundation of language evolution. This conceptual foundation stands as a guide to formulate genetic algorithms for optimization, the FFT for spectro-temporal transformation, and genetically optimized ASR-based HMMs for learning and generating. Finally, these formulae will be implemented in software through the processing programming language and computationally and digitally synthesized (compiled) and powered by a Linux-based computing system for an adaptive generative design language system that learns within a public space or from a community.

% ERICK: Do you want to keep this?
% In this work, we use these ideas as inspiration for a learning-shape generating system. Ultimately, the construction and future analysis of these physical and algorithmic models of cultural evolution provides a number of supporting models of social metrics, that could be utilized to oppose or support experimentally confirmed generating mechanisms of human culture.

\section{Design Approach}
This design system has been broken down into three design phases, where each phase corresponds to a \textit{jump} in the generative design process. In the beginning or the \textit{first phase}, the design language system has been specified through a combination of appealing aesthetic choices and randomly generated characteristics. That is to say, the first phase is the most arbitrary, as it is only with respect to one preferences at the time.

\paragraph{First Phase}
The \textit{first design phase} uses pre-defined specification for the \textit{color}, \textit{complexity}, \textit{shape}, and \textit{size} of the visualization components. Particularly, the colors of the shapes in the visualization are some values from within the RGB range, the shapes are chosen to be boxes  from the set $\in$ $\lbrace box, ellipse, sphere \rbrace$ which correspond to the pre-defined shapes in the \textit{processing programming language} \cite{reas2006processing}. In truth, this first phase is simply a base or bootstrap for the consecutive phases. Hence, this basic form allows the most concrete specification of the sound-based visualization. This phase does not incorporate any learning, and it simply a product of one individual preference.

\paragraph{Second Phase}
The \textit{second phase} works to create a more general visualization where the components (or specifications) can be chosen at anytime by the user. Thus, the complexity can be chosen from some value $\in$ $ C = \lbrace c_1, c_2, \ ... \ , c_n \rbrace$, and the colors can be chosen from some value $\in$ $RGB = \lbrace u_1, u_2, \ ... \ , u_n \rbrace$, and the shapes can be specified from $\in$ 
$P = \lbrace s_1, s_2, \ ... \ , s_n \rbrace$, and finally the size of the \textbf{visualization} can be some value chosen $\in$ $ S = \lbrace size_1, size_2, \ ... \ , size_n \rbrace$. 

\paragraph{Third Phase}
The \textit{final phase} or \textit{third phase} of the design system works to incorporate learning into the generation of the default design. Like the second phase, users can specify the design characteristics from within the set $C$, $P$, $RGB$, and $S$:
\begin{equation}
NORM &= C \cup RGB \cup P \cup S
\label{eq:third-phase}
\end{equation}
However, as users specify their visualization preferences, the system makes a copy or memory of these preferences, saving it into a collection of preferences, $NORM$. For example, one preference might be a higher weight or frequency of blue colored shapes, or conversely, a lower number of complexities will be selected out of for if low complexity is less frequent in $NORM$. As a result, the fittest individuals and resulting generated design language is some set of preferences that ascribes to this fit collection:

\subsection{Design System Software}
The system was written in the programming languages, \textit{Python} and \textit{Processing}. Specifically, the pj5 flavor of Processing was used to create the web-based visualization that is accessed by some Linux-computing system, which is connected to an output display via HDMI. The GA-ASR-HMM are written in Python and \textit{JavaScript} with its associated node.js packages. JavaScript was chosen for its flexibility and ease of implementation for hosting this visualization online. 

\subsection{Design System Hardware}
Practically, this system is running on a Raspberry Pi, which runs the JavaScript code for learning, the pj5 code for visualization, and connects a dynamic microphone and multimedia projector via HDMI. In theory, the system can be implemented on various computing platforms and associated operating systems; the Raspberry Pi was chosen because of its hardware specifications, in particular its networking and processing capabilities, as the visualization happens at 60 FPS. Hence, this system can be interpreted on any operating system that has such networking capabilities, sufficient storage, and the necessary peripherals and shown in Fig.~\ref{EvoLang12-SPENCERDESIGN.png}. 

% HAMZA-3: Could you please write a paragraph about using such a system to generate art in the style of notable artist
% HAMZA Notes: Please pay attention to the Design System Software and System Hardware section...
% subsection{Application of System}

\begin{figure}[H]
 \centering
 \includegraphics[width=0.90\textwidth]{EvoLang12-SPENCERDESIGN.png}
 \caption{The interactive design system consist of a mobile computing system (Raspberry Pi), a USB microphone, and a multimedia projector. The public provides input data which is then processed by the computing system to generate various shapes and novel structures throughout the day}
 \label{EvoLang12-SPENCERDESIGN.png}
\end{figure}

\section{Conclusion}
Presented in this document is a design system framework that attempts to generate the most preferred or fittest visualization as a function of public interactions. The system is inspired from basic cultural evolution concepts and entertainment applications of the fast Fourier transform. In the end, this system attempts to infer novel output 
(visualization) from random input (acoustic information), and a collection of environmental and internal constraints. This process is undertaken through a combination of Fourier analysis and genetically-optimized hidden-Markov models. As such, the focus of this system is  not necessarily providing an accurate representation of human cognition, and instead a framework for inferring and constructing structural representations for a learned public space.

% HAMZA-4: So after you read it trash this shit. Like the more scrutiny the better. Additionally, below are the section and subsection guidelines for this EvoLang12 Submissions. Please, take a look at these to make sure we're following everything.

% HAMZA-5: Please add or suggest any sections we should write

% ERICK: Make appropriate changes that Hamza suggest: sections, subsections, figures, etc.

% \section{Guidelines}

% \subsection{General Guidelines}

% We have provided eight files for use when producing a paper using latex. 

% \begin{enumerate}

% \item {\em evolang12.tex} --- the source for this document. 

% \item {\em evolang12.pdf} --- PDF generated from {\em evolang12.tex}.

% \item {\em evolang12.png} --- the figure file.

% \item {\em evolang12.bib} --- the bibliography file.

% \item {\em evolang12.cls} --- the class file that provides the higher
% level latex commands for the proceedings. \textbf{Do not change the contents of this file.}
 
% \item {\em apacite.bst} --- the APA bibliography style file.
  
% \item {\em apacite.sty} --- the package handling citations.

% \item {\em apacite.pdf} --- documentation for the APA packages.

% \end{enumerate}

% You can delete our sample text and replace it with your own
% contribution to the volume, although we recommend that you keep an initial version of the file for reference.  These files should work with standard latex2e.

% \subsection{Double-Blind Peer Review}

% The review process is double-blind.  Authors will not be told who reviews their paper and reviewers will not be told who the authors of the papers are.  Please keep in mind these guidelines for keeping your paper anonymous:

% \begin{enumerate}
% \item  \textbf{Do not include the names and affiliations of authors in the paper}

% Authors will add names and affiliations after the paper has been reviewed and accepted.  However, keep in mind that names and affiliations will take up space.  We suggest that authors include anonymous placeholders for names and affiliations to avoid problems with page limits (e.g. ``AUTHOR BBBBB \& AUTHOR CCCCC'').

% \item \textbf{Try not to reveal the identity of the authors indirectly}

% This can include the following steps:

% \begin{itemize}
% \item Use third person to refer to previous work by the authors.  e.g. instead of ``As we have previously shown, language is a complex system (Jones, 2012)'' use ``As was previously shown, language is a complex system (Jones, 2012)'', or more simply ``Language is a complex system (Jones, 2012)''.
% \item Do not eliminate essential self-references or other references but limit self-references only to papers that are relevant for those reviewing the submitted paper.
% \item Make sure figures do not contain any affiliation related identifier.
% \end{itemize}

% \end{enumerate}

% If the paper is accepted the authors will be required to submit a camera-ready version.  In the camera-ready version, the steps above can be reversed and author names, affiliations and acknowledgements etc. may be added.  \textbf{Again, please make sure that the papers will adhere to the space limitations once these changes are made.}  Of course, given the small size of the field it may not be possible to completely prevent reviewers from guessing the identity of the authors.  
% \subsection{Headings and Text}

% Please preserve the style of the headings, text font and line spacing in order to provide a uniform style for the proceedings volume.  Note that page numbers should not be included --- the final pagination of the volume will be done by the editors.


% \subsection{References and Citations}

% References and citations should be in the APA style, using the {\em  apacite.sty} and {\em apacite.bst} files provided.  We have included examples of reference style for various publication types in the References section and in {\em evolang12.bib}.

% \begin{description}
% \item [Citation Example 1:] \citeA{pinker_90_natural} argue that \ldots
% \item [Citation Example 2:] It has been argued \cite{pinker_90_natural} that \ldots
% \end{description}
% \nocite{tomasello_03_constructing,hauser_03_uniquely}

% For details on more complex citation commands, please consult {\em apacite.pdf}.

% \subsection{Footnotes}

% Footnotes are denoted by a character superscript in the
% text.\footnote{This is a footnote.}

% \subsection{Equations}

% Equations should be centered and numbered consecutively, as in
% Eq.~(\ref{eq:simple_equation}).

% \begin{equation}
% p = q + r
% \label{eq:simple_equation}
% \end{equation}

% \subsection{Tables}

% Tables should have a uniform style throughout the paper.  We would
% prefer the border lines to be of the style shown in Table~\ref{table1}
% --- single lines at top and bottom, no vertical lines at left or
% right.  Placement of inner lines is left to your judgement, but it
% generally looks better if they are kept to a minimum.

% Table captions should be placed at the top of the table, and are
% generated using the $\backslash$tablecaption command.  The text within
% the table should be $\backslash$footnotesize.


% \begin{table}[ht]
%   \tablecaption{An example table.  This caption is generated using the
%     $\backslash$tablecaption environment, and the table itself is in
%     $\backslash$footnotesize.}
% {\footnotesize
% \begin{tabular}{@{}cccc@{}}
% \hline
%  & Column 1 & Column 2 & Column 3\\
% \hline
% Row 1 & entry & entry & entry \\
% Row 2 & entry & entry & entry \\
% Row 3 & entry & entry & entry \\

% \hline
% \end{tabular}\label{table1}}
% \end{table}


% \subsection{Figures/Illustrations/Images}

% It is best to embed the figures in the text where they are first cited,
% e.g. see Fig.~\ref{inter}. Please ensure that all labels in the
% figures are legible regardless of whether they are drawn electronically or manually.  Very large figures and tables should be placed
% on a page by themselves.

% \begin{figure}[ht]
% \begin{center}
% \scalebox{0.6}{\includegraphics{evolang12.png}}
% \end{center}
% \caption{{\footnotesize An example graph.  All labels are legible, and
%     this caption is in $\backslash$footnotesize. \label{inter}}}
% \end{figure}

% The caption heading for a figure should be placed below that figure.
% The caption text should be $\backslash$footnotesize.

% \section{Supplementary Materials}

% There will be some support for supplementary materials.  All information necessary to understand and evaluate the submission should be included in the main paper.  Reviewers will not see the supplementary materials.  However, authors are encouraged to make data or code available for the final publication.  All supplementary materials should be submitted within a single zip file, which should also include a README.txt file describing the contents.  Supplementary materials should be referenced in the main text (e.g. ``see supplementary materials''). Please avoid appendices in the text and provide additional information in the supplementary materials instead. These will be hosted online along with the final proceedings but will not be considered during the review process.

% \section*{Acknowledgements}

% If you wish to acknowledge funding bodies etc., the acknowledgements may be placed in a separate, unnumbered section at the end of the text. Please replace acknowledgements with filler text for the submission stage to preserve anonymity. Please avoid appendices in the text and provide additional information in the supplementary materials instead. These will be hosted online along with the final proceedings but will not be considered during the review process.
\bibliographystyle{apacite}
\bibliography{evolang12} 

\end{document}
